# Telkom Paper Research API - Backend

FastAPI + DSPy backend for AI-powered paper research platform.

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py              # Package init
â”‚   â”œâ”€â”€ main.py                  # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py                # Settings & configuration
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ chat.py          # AI chat endpoints
â”‚   â”‚       â”œâ”€â”€ papers.py        # Paper search endpoints
â”‚   â”‚       â””â”€â”€ health.py        # Health check endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py            # Pydantic schemas
â”‚   â”‚   â””â”€â”€ exceptions.py        # Custom exceptions
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag.py               # RAG service with DSPy
â”‚   â”‚   â””â”€â”€ retriever.py         # Paper retriever
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ streaming.py         # SSE streaming utilities
â”œâ”€â”€ data/
â”‚   â””â”€â”€ papers.json              # Paper data (optional)
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ run.py                       # Convenience runner
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd backend
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env and add your API keys
```

### 3. Run the Server

```bash
# Activate virtual environment
.venv\Scripts\activate

# Option 1: Using run.py
python run.py

# Option 2: Using uvicorn directly
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Option 3: Using main.py
python -m app.main
```

## ğŸ“¡ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API info & available endpoints |
| `/health` | GET | Health check |
| `/papers/search` | GET/POST | Search papers by keyword |
| `/papers/list` | GET | List all papers |
| `/chat/basic` | POST | AI chat (streaming or sync) |
| `/chat/deep` | POST | Deep research (RLM) - TBD |

## ğŸ”§ Configuration

All configuration is done via environment variables (see `.env.example`):

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENROUTER_API_KEY` | Yes* | OpenRouter API key |
| `OPENAI_API_KEY` | Yes* | OpenAI API key (alternative) |
| `DSPY_MODEL` | No | Model to use (default: Gemini Pro) |
| `DSPY_MAX_WORKERS` | No | Async workers (default: 4) |
| `RETRIEVAL_TOP_K` | No | Papers per query (default: 3) |

*At least one API key is required.

## ğŸ§ª Testing

```bash
# Health check
curl http://localhost:8000/health

# Search papers
curl "http://localhost:8000/papers/search?query=machine+learning&limit=5"

# AI chat (non-streaming)
curl -X POST http://localhost:8000/chat/basic \
  -H "Content-Type: application/json" \
  -d '{"question": "What is deep learning?", "stream": false}'

# AI chat (streaming)
curl -X POST http://localhost:8000/chat/basic \
  -H "Content-Type: application/json" \
  -d '{"question": "What is deep learning?", "stream": true}'
```

## ğŸ“š Architecture

### RAG Flow

```
User Question
     â†“
PaperRetriever (keyword search)
     â†“
RAG Module (DSPy + ChainOfThought)
     â†“
Streaming Response (SSE)
```

### Services

- **PaperRetriever**: Simple keyword-based search (replaceable with vector search)
- **RAGService**: DSPy module for question answering with citations
- **Streaming Utils**: SSE formatting for real-time responses

## ğŸ”® Future Improvements

1. **Vector Search**: Replace keyword search with `dspy.retrievers.Embeddings`
2. **Conversation History**: Add Redis/DB for multi-turn conversations
3. **RLM Agent**: Implement recursive language model for deep research
4. **Authentication**: Add JWT-based auth
5. **Rate Limiting**: Protect API endpoints

## ğŸ“– Documentation

- See `docs/` for detailed implementation guides
- FastAPI docs: http://localhost:8000/docs (auto-generated)
- OpenAPI spec: http://localhost:8000/openapi.json
